{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ReaZwkzQSzxX",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:09:43.230721Z",
     "start_time": "2022-05-21T00:09:42.924519Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReaZwkzQSzxX",
    "outputId": "8d506d33-412b-4dc0-ed90-10ffe6cf3ddb"
   },
   "outputs": [],
   "source": [
    "is_train = True\n",
    "basic_epochs = 0\n",
    "local = 1\n",
    "if (local):\n",
    "    log_dir = '/home/zyp/w/d2l/classify_leave/log'\n",
    "    data_dir = '/home/zyp/w/d2l/classify_leave/data'\n",
    "    model_file = '/home/zyp/w/d2l/classify_leave/log/epochs'+str(basic_epochs)+'.model'\n",
    "else:\n",
    "    log_dir = '/content/log'\n",
    "    data_dir = '/content/data'\n",
    "    model_file = '/content/log/epochs'+str(basic_epochs)+'.model'\n",
    "    drive_log_dir = '/content/drive/MyDrive/colab/classify_leave/log'\n",
    "    drive_model_file = '/content/drive/MyDrive/colab/classify_leave/log/epochs'+str(basic_epochs)+'.model'\n",
    "    \n",
    "!mkdir -p $log_dir\n",
    "!mkdir -p $data_dir\n",
    "\n",
    "total_epochs = basic_epochs\n",
    "log_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Tv4Ip1AYMNT4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv4Ip1AYMNT4",
    "outputId": "c92698a9-f495-4cdb-8504-b3a5b5134bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Archive:  /content/data/classify-leaves.zip\n",
      "replace /content/data/images/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: 27153\n",
      "time: 23.4 s (started: 2022-05-20 07:24:05 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#显示运行时间\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime\n",
    "\n",
    "# 挂载 drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 准备数据集\n",
    "\n",
    "!cp /content/drive/MyDrive/colab/classify_leave/classify-leaves.zip /content/data\n",
    "!unzip /content/data/classify-leaves.zip -d /content/data/\n",
    "!ls /content/data/images/ | wc -l\n",
    "\n",
    "#!cp $drive_model_file /content/log/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fe3c458e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:09:57.368414Z",
     "start_time": "2022-05-21T00:09:57.365610Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe3c458e",
    "outputId": "603f095d-0b6a-48a3-f5c7-3e79face32b1"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from torchvision.io import read_image\n",
    "import logging\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c2834d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:11:08.695890Z",
     "start_time": "2022-05-21T00:11:08.548136Z"
    },
    "id": "c2834d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zyp/w/d2l/classify_leave/log/1.log\n",
      "abc\r\n",
      "abc\r\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename=log_dir + '/1.log', level=logging.DEBUG, format='%(message)s')\n",
    "logging.info('abc')\n",
    "log_file = log_dir + '/1.log'\n",
    "print(log_file)\n",
    "!cat $log_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "s1sb0pS2oX2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:11:12.525265Z",
     "start_time": "2022-05-21T00:11:12.521955Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1sb0pS2oX2c",
    "outputId": "1685cc15-b573-4fa7-f1fa-314b33c142b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ff417cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:11:15.245005Z",
     "start_time": "2022-05-21T00:11:15.227432Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff417cdf",
    "outputId": "5ab33866-abcc-41d4-dde9-5caf00f9aafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                image                  label\n",
      "0        images/0.jpg       maclura_pomifera\n",
      "1        images/1.jpg       maclura_pomifera\n",
      "2        images/2.jpg       maclura_pomifera\n",
      "3        images/3.jpg       maclura_pomifera\n",
      "4        images/4.jpg       maclura_pomifera\n",
      "...               ...                    ...\n",
      "9171  images/9171.jpg        aesculus_glabra\n",
      "9172  images/9172.jpg           quercus_alba\n",
      "9173  images/9173.jpg      cercis_canadensis\n",
      "9174  images/9174.jpg  gleditsia_triacanthos\n",
      "9175  images/9175.jpg       maclura_pomifera\n",
      "\n",
      "[9176 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_train_label = pd.read_csv(data_dir + '/train.csv')\n",
    "l = len(all_train_label)\n",
    "train_set = all_train_label[0: math.floor(l/2)]\n",
    "validation_set = all_train_label[math.floor(l/2):]\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fa97f8a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:11:17.908116Z",
     "start_time": "2022-05-21T00:11:17.903698Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa97f8a0",
    "outputId": "98fbeb9e-9720-43c4-8e81-739b19683d23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('abies_concolor', 0), ('abies_nordmanniana', 1), ('acer_campestre', 2), ('acer_ginnala', 3)]\n",
      "[(0, 'abies_concolor'), (1, 'abies_nordmanniana'), (2, 'acer_campestre'), (3, 'acer_ginnala')]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "leave_class = sorted(list(set(all_train_label['label'])))\n",
    "class_to_idx = dict(zip(leave_class, range(len(leave_class)))) \n",
    "idx_to_class = {v:k for k, v in class_to_idx.items()}\n",
    "\n",
    "print(list(class_to_idx.items())[0:4])\n",
    "print(list(idx_to_class.items())[0:4])\n",
    "print(class_to_idx['abies_nordmanniana'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d60d5081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:11:25.185525Z",
     "start_time": "2022-05-21T00:11:25.157949Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d60d5081",
    "outputId": "5332e0ec-8093-4845-bd77-73d9f5ec2b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9176 9177 8800\n"
     ]
    }
   ],
   "source": [
    "class LeaveDataset(Dataset):\n",
    "    \n",
    "    all_train_label = pd.read_csv(data_dir + '/train.csv')\n",
    "    test_label = pd.read_csv(data_dir + '/test.csv')\n",
    "    offset = math.floor(len(all_train_label) / 2)\n",
    "    train_mode = \"train\"\n",
    "    validation_mode = \"validation\"\n",
    "    \n",
    "    def __init__(self, mode):\n",
    "        self.mode = mode        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        all_train_label = LeaveDataset.all_train_label.copy(deep=False)\n",
    "        test_label = LeaveDataset.test_label.copy(deep=False)\n",
    "\n",
    "        if self.mode == LeaveDataset.train_mode:\n",
    "            img_file, label = all_train_label.iloc[idx][0], all_train_label.iloc[idx][1]\n",
    "        elif self.mode == LeaveDataset.validation_mode:\n",
    "            idx = LeaveDataset.offset + idx\n",
    "            img_file, label = all_train_label.iloc[idx][0], all_train_label.iloc[idx][1]\n",
    "        else:\n",
    "            img_file = test_label.iloc[idx][0]\n",
    "            \n",
    "        img = read_image(str(data_dir + '/' + img_file))\n",
    "        if self.mode == LeaveDataset.train_mode:\n",
    "            t = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomResizedCrop(size=(224, 224), scale=(0.5, 1)),\n",
    "                transforms.ConvertImageDtype(torch.float),\n",
    "            ])\n",
    "        else:\n",
    "            t = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ConvertImageDtype(torch.float),\n",
    "            ])         \n",
    "        \n",
    "        img = t(img)\n",
    "        if 'label' in locals():\n",
    "            label = class_to_idx[label]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        test_label = LeaveDataset.test_label.copy(deep=False)\n",
    "\n",
    "        if self.mode == LeaveDataset.train_mode:\n",
    "            return LeaveDataset.offset\n",
    "        elif self.mode == LeaveDataset.validation_mode:\n",
    "            return len(all_train_label) - LeaveDataset.offset \n",
    "        else:\n",
    "            return len(test_label)\n",
    "\n",
    "        \n",
    "training_data = LeaveDataset(\"train\")\n",
    "validation_data = LeaveDataset(\"validation\")\n",
    "test_data = LeaveDataset(\"test\")\n",
    "print(len(training_data), len(validation_data), len(test_data))\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "45f4050b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:12:21.870351Z",
     "start_time": "2022-05-21T00:11:36.521148Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45f4050b",
    "outputId": "8b8b8bfc-8c71-42a8-ac28-af11f7aec43f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/zyp/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce25733204074a27bcf592a313f699fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "#model = models.resnet50(pretrained=False)\n",
    "#model.load_state_dict(torch.load(model_file, map_location=torch.device(device)))\n",
    "\n",
    "model.train(is_train)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5caca424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:12:25.976252Z",
     "start_time": "2022-05-21T00:12:25.973369Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5caca424",
    "outputId": "f71782a0-01f4-40cc-b1bb-fc99bcc40a10"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Initialize the loss function / optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ce6e0a1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:12:37.833850Z",
     "start_time": "2022-05-21T00:12:28.434844Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce6e0a1b",
    "outputId": "fb843115-8c49-48a2-9726-2c0568f5a21f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78,  78,  78,  78,  78,  78, 174,  28,  78,  28,  78, 130,  78, 130,\n",
      "         28,  78,  78,  28,  78, 174,  78,  78, 130,  28,  78,  28, 174, 130,\n",
      "         78, 174, 130,  10,  28,  78,  58,  78,  78,  10,  78,  10, 174,  78,\n",
      "         10,  10,  58,  10,  28, 130, 130,  28, 130, 130,  28,  10, 130,  28,\n",
      "         78,  78,  28, 174,  10,  58,  28, 130])\n",
      "tensor([852, 879, 588, 758, 512, 790, 749, 356, 700, 426, 859, 980, 956, 608,\n",
      "        788, 641, 515, 793, 859, 329, 373, 943, 827, 530, 488, 455, 748, 844,\n",
      "        859, 421, 749,  49,  45,  36, 457, 818, 891, 968, 577, 304, 868, 391,\n",
      "        600, 311, 616, 532, 494, 448, 608, 431, 124,  14, 784, 745,  78, 749,\n",
      "        475, 494, 611, 551, 428, 566, 626, 469])\n",
      "maclura_pomifera\n"
     ]
    }
   ],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    print(y)\n",
    "    print(pred.argmax(1))\n",
    "    print(idx_to_class[78])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "be5d5ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:12:40.462403Z",
     "start_time": "2022-05-21T00:12:40.457292Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be5d5ffd",
    "outputId": "0db35f07-1fd4-41e2-fcc0-7a37d64fdb2d"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            log = f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\"\n",
    "            logging.info(log)\n",
    "            print(log)\n",
    "        \n",
    "    correct /= size\n",
    "    log = f\"[Train] Accuracy: {(100*correct):>0.1f}% \\n\"\n",
    "    print(log)\n",
    "    logging.info(log)\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    log = f\"[Test] Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    print(log)\n",
    "    logging.info(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "31df4083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T01:04:34.658183Z",
     "start_time": "2022-05-21T00:39:57.960053Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31df4083",
    "outputId": "8c7754aa-18c3-4536-e66b-213525decece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.752347  [    0/ 9176]\n",
      "loss: 5.846805  [ 6400/ 9176]\n",
      "[Train] Accuracy: 5.9% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#validation_loop(validation_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "925f1360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T01:36:22.756525Z",
     "start_time": "2022-05-20T01:25:16.091883Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "925f1360",
    "outputId": "4c0574df-ff65-4400-f636-9ebcccaf3f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.444763  [    0/ 9176]\n",
      "loss: 0.336020  [ 6400/ 9176]\n",
      "[Train] Accuracy: 91.6% \n",
      "\n",
      "[Test] Accuracy: 79.8%, Avg loss: 0.733492 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.433996  [    0/ 9176]\n",
      "loss: 0.292215  [ 6400/ 9176]\n",
      "[Train] Accuracy: 91.7% \n",
      "\n",
      "[Test] Accuracy: 80.1%, Avg loss: 0.729760 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.414370  [    0/ 9176]\n",
      "loss: 0.349467  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.0% \n",
      "\n",
      "[Test] Accuracy: 80.5%, Avg loss: 0.718748 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.288408  [    0/ 9176]\n",
      "loss: 0.238979  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.1% \n",
      "\n",
      "[Test] Accuracy: 80.2%, Avg loss: 0.719458 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.395620  [    0/ 9176]\n",
      "loss: 0.350331  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.5% \n",
      "\n",
      "[Test] Accuracy: 80.2%, Avg loss: 0.719019 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.445504  [    0/ 9176]\n",
      "loss: 0.302794  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.5% \n",
      "\n",
      "[Test] Accuracy: 80.5%, Avg loss: 0.714595 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.301539  [    0/ 9176]\n",
      "loss: 0.173627  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.8% \n",
      "\n",
      "[Test] Accuracy: 80.8%, Avg loss: 0.708111 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.299064  [    0/ 9176]\n",
      "loss: 0.261436  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.4% \n",
      "\n",
      "[Test] Accuracy: 80.9%, Avg loss: 0.704309 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.283351  [    0/ 9176]\n",
      "loss: 0.262663  [ 6400/ 9176]\n",
      "[Train] Accuracy: 92.8% \n",
      "\n",
      "[Test] Accuracy: 80.8%, Avg loss: 0.706541 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.287658  [    0/ 9176]\n",
      "loss: 0.221581  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.0% \n",
      "\n",
      "[Test] Accuracy: 81.0%, Avg loss: 0.702258 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.260289  [    0/ 9176]\n",
      "loss: 0.239085  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.4% \n",
      "\n",
      "[Test] Accuracy: 80.9%, Avg loss: 0.691902 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.365367  [    0/ 9176]\n",
      "loss: 0.183368  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.5% \n",
      "\n",
      "[Test] Accuracy: 80.9%, Avg loss: 0.694113 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.276818  [    0/ 9176]\n",
      "loss: 0.263120  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.4% \n",
      "\n",
      "[Test] Accuracy: 81.1%, Avg loss: 0.689377 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.324724  [    0/ 9176]\n",
      "loss: 0.229590  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.8% \n",
      "\n",
      "[Test] Accuracy: 81.1%, Avg loss: 0.689047 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.346906  [    0/ 9176]\n",
      "loss: 0.182991  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.7% \n",
      "\n",
      "[Test] Accuracy: 81.1%, Avg loss: 0.684474 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.278399  [    0/ 9176]\n",
      "loss: 0.223954  [ 6400/ 9176]\n",
      "[Train] Accuracy: 93.7% \n",
      "\n",
      "[Test] Accuracy: 81.4%, Avg loss: 0.682370 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.317086  [    0/ 9176]\n",
      "loss: 0.276292  [ 6400/ 9176]\n",
      "[Train] Accuracy: 94.2% \n",
      "\n",
      "[Test] Accuracy: 81.5%, Avg loss: 0.678404 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.342965  [    0/ 9176]\n",
      "loss: 0.192302  [ 6400/ 9176]\n",
      "[Train] Accuracy: 94.0% \n",
      "\n",
      "[Test] Accuracy: 81.5%, Avg loss: 0.671864 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.249467  [    0/ 9176]\n",
      "loss: 0.155643  [ 6400/ 9176]\n",
      "[Train] Accuracy: 94.1% \n",
      "\n",
      "[Test] Accuracy: 81.6%, Avg loss: 0.669526 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.376463  [    0/ 9176]\n",
      "loss: 0.218824  [ 6400/ 9176]\n",
      "[Train] Accuracy: 94.0% \n",
      "\n",
      "[Test] Accuracy: 81.5%, Avg loss: 0.670176 \n",
      "\n",
      "Done!\n",
      "save model at epochs 120\n",
      "total 135M\n",
      "drwxr-xr-x 2 root root 4.0K May 20 08:06 .\n",
      "drwxr-xr-x 1 root root 4.0K May 20 06:53 ..\n",
      "-rw-r--r-- 1 root root 5.6K May 20 08:06 1.log\n",
      "-rw------- 1 root root  45M May 20 07:24 epochs100.model\n",
      "-rw-r--r-- 1 root root  45M May 20 08:06 epochs120.model\n",
      "-rw------- 1 root root  45M May 20 06:53 epochs50.model\n",
      "time: 35min 21s (started: 2022-05-20 07:30:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    total_epochs+=1\n",
    "    log = f\"Epoch {total_epochs}\\n-------------------------------\"\n",
    "    print(log)\n",
    "    logging.info(log)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_loop(validation_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"save model at epochs \" + str(total_epochs))\n",
    "torch.save(model.state_dict(), log_dir+'/epochs' + str(total_epochs) + '.model')\n",
    "\n",
    "!ls -alh $log_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "IxYEY0rDuuxR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxYEY0rDuuxR",
    "outputId": "cdbb93d3-fddc-46ec-be64-91e515ba62ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 751 ms (started: 2022-05-20 08:06:08 +00:00)\n"
     ]
    }
   ],
   "source": [
    "!mv /content/log/*.model $drive_log_dir\n",
    "drive_log_file = drive_log_dir + \"/log.epochs\" + str(basic_epochs) + \".\" + str(log_num)\n",
    "!cp /content/log/1.log $drive_log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3ee47",
   "metadata": {},
   "source": [
    "---\n",
    "## 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd3a9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T00:13:06.485110Z",
     "start_time": "2022-05-21T00:12:45.995613Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集预测\n",
    "test_pred = torch.tensor([], dtype=torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        test_pred = torch.hstack((test_pred, pred.argmax(1)))\n",
    "        \n",
    "print(test_pred.shape)\n",
    "\n",
    "test_class = []\n",
    "for i in enumerate(test_pred.numpy()):\n",
    "    test_class.append(idx_to_class[i[1]])\n",
    "print(len(test_class))\n",
    "test_class2 = pd.DataFrame(test_class, columns=['label'])\n",
    "\n",
    "result = pd.concat([LeaveDataset.test_label, test_class2], axis=1)\n",
    "result.to_csv(log_dir + \"/result.csv\", index=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classify_leaves3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
